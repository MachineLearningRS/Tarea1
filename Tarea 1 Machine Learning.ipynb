{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"cite2c-biblio\"></div><img src=\"escudo_utfsm.gif\" style=\"float:right;height:100px\">\n",
    "<img src=\"IsotipoDIisocolor.png\" style=\"float:left;height:100px\">\n",
    "<center>\n",
    "    <h1> INF-493 - Machine Learning</h1>\n",
    "    <h1> Tarea 1 - Metodos Lineales para Regresión </h1>\n",
    "</center>\n",
    "<p>\n",
    "<br><center>_Javier Reyes_<strong> - </strong>_javier.reyes.12@sansano.usm.cl_<strong> - </strong>_201273524-6_ </center>\n",
    "<br><center>_Marco Salinas_<strong> - </strong>_marco.salinas.12@sansano.usm.cl_<strong> - </strong>_201273589-0_ </center>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  1 Regresión Lineal Ordinaria (LSS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(a)** Construya un dataframe con los datos a analizar descargándolos desde la plataforma como se indicó.\n",
    "Explique por qué se realiza la línea 4.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv(\"kc_house_data.csv\")\n",
    "df.drop(['id','date','zipcode',],axis=1,inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<p  style=\"text-align: justify;\">\n",
    "    La función _drop_ utilizada en el código anterior, elimina las columnas \"id\", \"date\" y \"zipcode\" del dataframe, que anteriormente habiamos leido. Esto se realiza debido a que dichos atributos no son relevantes para el estudio del dataframe.\n",
    "</p>\n",
    "\n",
    "<p  style=\"text-align: justify;\"> \n",
    "    **(b)** Describa brevemente el dataset a utilizar.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "print(\"------------------------------------------\")\n",
    "df.info()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<p  style=\"text-align: justify;\">\n",
    "    El dataset posee $21613$ datos, los cuales poseen $18$ atributos cada uno donde describen las distintas caracteristicas de las casa, por ejemplo, el precio de venta de la casa, la cantidad de habitaciones y baños, la cantidad de metros cuadrados construidos, y los del terreno. Además, de otras especificaciones tecnicas como el año de construcción, el año de la ultima renovacion, el promedio de metros cuadrados construidos y de terreno de las 15 casas más cercanas. \n",
    "</p>\n",
    "\n",
    "<p  style=\"text-align: justify;\">\n",
    "    Todos estos datos nos ayudarian a tomar decisiones sobre cual casa se deberia comprar.\n",
    "</p>\n",
    "\n",
    "<p  style=\"text-align: justify;\">\n",
    "    **(c)** Normalice los datos antes de trabajar y aplique una transformación adecuada a la variable a predecir.\n",
    "Explique la importancia/conveniencia de realizar estas dos operaciones.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "df_scaled = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "df_scaled['price'] = np.log(df['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\">\n",
    "    **(d)** Realice una regresión lineal de mínimos cuadrados básica. Explique la importancia/conveniencia del\n",
    "paso 4 y los argumentos que se deben entregar a la función que implementa la regresión lineal.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model as lm\n",
    "X = df_scaled.iloc[:,1:] #use .ix instead, in older pandas version\n",
    "N = X.shape[0]\n",
    "X.insert(X.shape[1], 'intercept', np.ones(N))\n",
    "y = df_scaled['price']\n",
    "#mascara estatica con el 70% de los datos\n",
    "mascara = np.zeros(len(X))\n",
    "limit = int(len(X)*0.7)\n",
    "mascara[:limit] = 1\n",
    "istrain = mascara== 1\n",
    "Xtrain = X[istrain]\n",
    "ytrain = y[istrain]\n",
    "Xtest = X[np.logical_not(istrain)]\n",
    "ytest = y[np.logical_not(istrain)]\n",
    "linreg = lm.LinearRegression(fit_intercept = False)\n",
    "linreg.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\">\n",
    "    **(e)** Construya una tabla con los pesos y Z-score correspondientes a cada predictor (variable). ¿Qué variables\n",
    "están más correlacionadas con la respuesta? Si usáramos un nivel de significación del 5%. ¿Qué es lo\n",
    "que observa y cuál puede ser la causa?\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as sc\n",
    "N = Xtrain.shape[0]\n",
    "p = Xtrain.shape[1]\n",
    "X = Xtrain.as_matrix() #datos pasados a matriz\n",
    "invXTX = np.linalg.inv(np.mat(X.T)*np.mat(X)) #matriz inversa de X.T*X \n",
    "b_hat_left = np.mat(invXTX)*np.mat(X.T) #matriz inversa de X.T*X por X.T\n",
    "b_hat = np.squeeze(np.asarray(b_hat_left.dot(ytrain)))# inversa(X.T*X)*X.T*y\n",
    "yhat_train = linreg.predict(Xtrain) # y gorro desde predicción regresión lineal aplicada a los datos X de entrenamiento\n",
    "aux_sig = np.mean(np.power(yhat_train - ytrain, 2))#estimador de varianza \n",
    "cte = 1/(N-p-1) #N datos con p inputs\n",
    "Naux_sig = N*aux_sig\n",
    "est_sig = cte*Naux_sig#estimador de sigma\n",
    "v_j = np.diag(invXTX)\n",
    "wz = np.empty((18,2))\n",
    "for i in range(0,18):\n",
    "    wz[i][0] = b_hat[i]\n",
    "    wz[i][1] = b_hat[i]/(np.power(est_sig*v_j[i],0.5))\n",
    "df = pd.DataFrame(wz, columns = [\"Peso\",\"Z-score\"])\n",
    "df.index = [\"bedrooms\",\"bathrooms\",\"sqft_living\",\"sqft_lot\",\"floors\",\"waterfront\",\"view\",\"condition\",\n",
    "\"grade\",\"sqft_above\",\"sqft_basement\",\"yr_built\",\"yr_renovated\",\"lat\",\"long\",\"sqft_living15\",\"sqft_lot15\",\"intercept\"] \n",
    "t_value = stats.t.ppf(1-0.05, N-p-1)\n",
    "print(\"Intervalo de confianza con un 5%% de significancia aplicando t_student = [%f,%f]\"%(-1*t_value,t_value))\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\">\n",
    "    Las variables más correlocionadas son: $grade = 0.233575$, $sqft-living15 = 0.085933$ y $floors = 0.08539$\n",
    "    donde grade es la variable con más correlación con la respuesta.<br>\n",
    "    Los <b><i>Z-Score</i></b> calculados se obtienen de la siguiente manera:\n",
    "   <br><br><center>\n",
    "   $\\begin{eqnarray}\n",
    "   z_j = \\frac{\\hat{\\beta_j}}{\\hat{\\sigma} \\sqrt{v_j}}\n",
    "   \\end{eqnarray}$\n",
    "   </center><br><br>\n",
    "   Donde:\n",
    "   <center>\n",
    "   $\\begin{eqnarray}\n",
    "      \\hat{\\beta_j} &=& (X^TX)^{-1}X^Ty \\\\\n",
    "      v_J &=& Diag(X^TX)^{-1})\\\\\n",
    "      \\hat{\\sigma^2} &=& \\frac{1}{N-p-1}\\sum_{i=1}^{N}(y_i - \\hat{y_i})^2 \n",
    "   \\end{eqnarray}$\n",
    "   </center><br><br>\n",
    "    El comportamiento de los <b><i>Z-Score</i></b> está dominado una distribución <b><i>T-Student</i></b> con $N-p-1 = 15110$ grados de libertad, donde el intervalo de confianza que se obtiene para estos datos de entrenamiento y sus predicciones con grado de significancia del <b>5%</b>  es $[-1.644954,1.644954]$. Con esto se puede observar que hay 4 atributos que tiene valor absoluto menor a $1.644954$, los cuales son:<br><br>\n",
    "    <li>$sqft-living = |8.031012e-07|$</li>\n",
    "    <li>$sqft-above = |6.555770e-06|$</li>\n",
    "    <li>$sqft-basement = |1.065057e-05|$</li>\n",
    "    <li>$long = |1.58967e+00|$</li>\n",
    "    <br>\n",
    "    $\\therefore$ Estos 4 atributos no son significantes para elegir qué casa comprar. \n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\">\n",
    "    **(f)** Proponga un método para corregir lo observado (Hint: inspírese en los métodos de feature engineering\n",
    "de las siguiente secciones). Verifíquelo mediante los Z-score presentados en la pregunta *(e)*.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(linreg, Xtrain, ytrain,scoring=\"neg_mean_squared_error\", cv=5)\n",
    "lam = min(scores)#el mínimo cross validation para penalizar en los Ridge values\n",
    "U, s, V = np.linalg.svd(X, full_matrices=False)#representación SVD de X\n",
    "D = np.diag(s)\n",
    "ridge_num = D.dot(U.T).dot(ytrain)\n",
    "for i in range(0,D.shape[0]):\n",
    "    ridge_num[i] = ridge_num[i]/(np.power(D[i][i],2)+lam)\n",
    "for i in range(0,18):\n",
    "    wz[i][0] = ridge_num[i]\n",
    "    wz[i][1] = ridge_num[i]/(np.power(est_sig*v_j[i],0.5))\n",
    "df = pd.DataFrame(wz, columns = [\"Bridge Peso\",\"Bridge Z-score\"])\n",
    "df.index = [\"bedrooms\",\"bathrooms\",\"sqft_living\",\"sqft_lot\",\"floors\",\"waterfront\",\"view\",\"condition\",\n",
    "\"grade\",\"sqft_above\",\"sqft_basement\",\"yr_built\",\"yr_renovated\",\"lat\",\"long\",\"sqft_living15\",\"sqft_lot15\",\"intercept\"] \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\">\n",
    "    Para poder corregir la significancia de los Z-Score de los 4 atributos anteriormente nombrados, se utiliza la técnica de regresión <b><i>Ridge</i></b>, en donde se calculan los <b><i>Cross Validation</i></b> posibles y se escojé el mínimo para penalizar los pesos.<br><br>\n",
    "    Primero se utiliza la descomposición $SVD$ de la matrix $X$, quedando la siguiente igualdad:\n",
    "    <br><br><center>\n",
    "    $\\begin{eqnarray}\n",
    "        X\\hat{\\beta}^{Ridge}_j &=& X(X^TX)^{-1}X^Ty\\\\\n",
    "                               &=& UD(D^2+\\lambda I)^{-1}DU^Ty\\\\\n",
    "                               &=& \\sum_{j=1}^{p}u_j\\frac{d_j^2}{d^2_j + \\lambda}u^Ty\n",
    "     \\end{eqnarray}$\n",
    "    <br><br></center>\n",
    "    Notar que al descomponer la matrix $X$ en su forma de $SVD$, se anula $U$ y $V$ debido a su ortonormalidad $U^TU=I$.<br>\n",
    "    Una vez obtenido el $\\lambda$, se reemplaza $\\hat{\\beta_j}$ por $\\hat{\\beta}^{Ridge}_j$,los cuales se calculan de la siguiente manera:\n",
    "   <br><br><center>\n",
    "   $\\begin{eqnarray}\n",
    "       \\hat{\\beta}^{Ridge}_j = \\sum_{j=1}^{p}\\frac{d_j}{d^2_j + \\lambda}u^T_jy\n",
    "   \\end{eqnarray}$\n",
    "   </center><br><br>\n",
    "      Reemplazando los nuevos valores del estimador, se puede ver un cambio en los atributos en un orden de $10^5$. Aún así, no fue posible modificar la significancia de todos los atributos anteriormente descartados, el único atributo que alcanzó un valor absoluto mayor a $1.644954$ fue $long$.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\">\n",
    "    **(g)** Estime el error de predicción del modelo usando validación cruzada con un número de folds igual a $K\n",
    "= 5$ y $K = 10$. Recuerde que para que la estimación sea razonable, en cada configuración (_fold_) debería\n",
    "reajustar los pesos del modelo. Mida el error real del modelo sobre el conjunto de pruebas, compare y\n",
    "concluya.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_test = linreg.predict(Xtest)\n",
    "mse_test = np.mean(np.power(yhat_test - ytest, 2))\n",
    "print('El error de predición real usando el test_set es %f'%mse_test)\n",
    "from sklearn import cross_validation\n",
    "Xm = Xtrain.as_matrix()\n",
    "ym = ytrain.as_matrix()\n",
    "\n",
    "k_fold = cross_validation.KFold(len(Xm),5)\n",
    "mse_cv = 0\n",
    "for k, (train, val) in enumerate(k_fold):\n",
    "    linreg = lm.LinearRegression(fit_intercept = False)\n",
    "    linreg.fit(Xm[train], ym[train])\n",
    "    yhat_val = linreg.predict(Xm[val])\n",
    "    mse_fold = np.mean(np.power(yhat_val - ym[val], 2))\n",
    "    mse_cv += mse_fold\n",
    "mse_cv = mse_cv / 5\n",
    "print('El error de prediccion usando CV con K=5 es %f'%mse_cv)\n",
    "\n",
    "k_fold = cross_validation.KFold(len(Xm),10)\n",
    "mse_cv = 0\n",
    "for k, (train, val) in enumerate(k_fold):\n",
    "    linreg = lm.LinearRegression(fit_intercept = False)\n",
    "    linreg.fit(Xm[train], ym[train])\n",
    "    yhat_val = linreg.predict(Xm[val])\n",
    "    mse_fold = np.mean(np.power(yhat_val - ym[val], 2))\n",
    "    mse_cv += mse_fold\n",
    "mse_cv = mse_cv / 10\n",
    "print('El error de prediccion usando CV con K=10 es %f'%mse_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\">\n",
    "    Si se utiliza $K=5$, en cada iteración habrá un $80\\%$ de los datos para entrenar y $20\\%$ para validar, en contraste con el 90% de datos de entranimiento y 10% de datos de validación con $K=10$. Al utilizar mayor cantidad de datos de entrenamiento habrá menor error, pero a costa del <b><i>overfitting</i></b> (sobreajuste al entrenamiento) que puede causar el entrenamiento con una cantidad considerable de datos.<br>\n",
    "Al apreciar el error real respecto a los de predición de cross-validation, se observa que los resultados obtenidos son lo suficientemente buenos como para concluir qué casas comprar dependiendo de los atributos dados.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\">\n",
    "    **(h)** Mida los errores de predicción para cada dato de entrenamiento. Utilizando un \"quantile-quantile plot\"\n",
    "determine si es razonable la hipótesis de normalidad sobre los residuos del modelo.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab\n",
    "import scipy.stats as stats\n",
    "%matplotlib inline\n",
    "pylab.figure(figsize=(15,10))\n",
    "errors = yhat_train - ytrain\n",
    "stats.probplot(errors,dist=\"norm\",plot=pylab)\n",
    "pylab.show()\n",
    "print(\"error promedio entre hipótesis de normalidad y datos de entrenamiento = \", abs(errors.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\">\n",
    "    Se puede apreciar en el gráfico, que hay una gran cantidad de datos que se aproximan a la hipótesis de normalidad, por lo que sugiere que los datos de entrenamientos son buenos para hacer estimaciones. Esto se puede corroborar al calcular la media de los errores de entrenamiento, la cual es de $0.00012944196138753425$.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  2 Selección de Atributos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\">\n",
    "    **(a)** Construya una función que implemente Forward Step-wise Selection (FSS). Es decir, partiendo con un\n",
    "modelo sin predictores (variables), agregue un predictor a la vez, re-ajustando el modelo de regresión\n",
    "en cada paso. Para seleccionar localmente una variable, proponga/implemente un criterio distinto al\n",
    "utilizado en el código de ejemplo. Construya un gráfico que muestre el error de entrenamiento y el error\n",
    "de pruebas como función del número de variables en el modelo. Ordene el eje x de menor a mayor.\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "\n",
    "def fss(x, y, names_x, test_data, k=10000):\n",
    "    p = x.shape[1] - 1\n",
    "    k = min(p, k)\n",
    "    names_x = np.array(names_x)\n",
    "    remaining = list(range(0, p))\n",
    "    selected = [p]\n",
    "    training_error = []\n",
    "    test_error = []\n",
    "    current_score = 0.0\n",
    "    best_new_score = 0.0\n",
    "    while remaining and len(selected) <= k:\n",
    "        score_candidates = []\n",
    "        for candidate in remaining:\n",
    "            model = lm.LinearRegression(fit_intercept=False)\n",
    "            indexes = selected + [candidate]\n",
    "            X_train = x[:, indexes]\n",
    "            model.fit(X_train, y)\n",
    "            predicted_value_train = model.predict(X_train)\n",
    "            residual_value_train = predicted_value_train - y\n",
    "            X_test, y_test = test_data\n",
    "            X_test = X_test[:, indexes]\n",
    "            predicted_value_test = model.predict(X_test)\n",
    "            residual_value_test = predicted_value_test - y_test\n",
    "            mse_train = np.mean(np.power(residual_value_train, 2))\n",
    "            mse_test = np.mean(np.power(residual_value_test, 2))\n",
    "            var = (mse_train * X_train.shape[0]) / (X_train.shape[0] - X_train.shape[1] - 1)\n",
    "            diag_values = np.diag(np.linalg.pinv(np.dot(X_train.T, X_train)))\n",
    "            z_score = np.divide(model.coef_, np.sqrt(np.multiply(var, diag_values)))\n",
    "            z_score_candidate = z_score[-1]\n",
    "            score_candidates.append((z_score_candidate, mse_train, mse_test, candidate))\n",
    "        score_candidates.sort()\n",
    "        z_score, best_new_score_, mse_test_, best_candidate = score_candidates.pop()\n",
    "        if best_candidate >= len(names_x):\n",
    "            break\n",
    "        remaining.remove(best_candidate)\n",
    "        selected.append(best_candidate)\n",
    "        training_error.append((len(selected), best_new_score_))\n",
    "        test_error.append((len(selected), mse_test_))\n",
    "        #print(\"selected= %s...\" % names_x[best_candidate])\n",
    "        #print(\"totalvars=%d, mse = %f\" % (len(indexes), best_new_score_))\n",
    "    return selected, training_error, test_error\n",
    "\n",
    "X = df_scaled.iloc[:,1:]\n",
    "names_regressors = X.columns[:-1]\n",
    "N = X.shape[0]\n",
    "X.insert(X.shape[1], 'intercept', np.ones(N))\n",
    "y = df_scaled['price']\n",
    "Xtrain = X[istrain]\n",
    "ytrain = y[istrain]\n",
    "Xtest = X[np.logical_not(istrain)]\n",
    "ytest = y[np.logical_not(istrain)]\n",
    "Xm_train = Xtrain.as_matrix()\n",
    "ym_train = ytrain.as_matrix()\n",
    "Xm_test = Xtest.as_matrix()\n",
    "ym_test = ytest.as_matrix()\n",
    "selected, points_training, points_test = fss(Xm_train, ym_train, names_regressors, (Xm_test, ym_test))\n",
    "x_test= []\n",
    "y_test= []\n",
    "for x in points_test:\n",
    "    x_test.append(x[0]-1)\n",
    "    y_test.append(x[1])\n",
    "x_train=[]\n",
    "y_train=[]\n",
    "for x in points_training:\n",
    "    x_train.append(x[0]-1)\n",
    "    y_train.append(x[1])\n",
    "plt.plot(x_train, y_train, label='Training Set')\n",
    "plt.plot(x_test, y_test, label='Testing Set')\n",
    "plt.xlim(min(x_train), max(x_train))\n",
    "plt.legend()\n",
    "plt.xlabel('Cantidad de predictores')\n",
    "plt.ylabel('Error de predicción')\n",
    "plt.title('Train error vs Test error con FSS')\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\">\n",
    "    Se utiliza primero que todo <b><i>FSS</i></b> para ir escogiendo los atributos que generan el menor error considerando los <b><i>Z-Score</i></b> como método de tolerancia.<br>\n",
    "    Del gráfico se ve que ambos sets, tanto el de entrenamiento como el de testeo tienen muy poca variación, esto comprueba o reafirma la calidad de los datos de entrenamiento, ya que como se vio en el punto <b><i>h)</i></b>, el error entre los datos de entrenamiento y de testeo es muy pequeño, por lo que en este caso en específico, no ocurre un overfitting al considerar todas las variables en los datos de entrenamiento. <br>\n",
    "    En el gráfico se plasma que el error de predicción disminuye conforme se agregan atributos, este comportamiento es consecuente con todos los resultados anteriormente obtenidos que califican a estos datos de entrenamientos como una buena elección para testearlos, ya que la diferencia de error entre los datos de entrenamiento y los de testeo es del orden de $10^{-2}$.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\">\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  3 Regularización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\">\n",
    "    **(a)** Ajuste un modelo lineal utilizando \"Ridge Regression\", es decir, regularizando con la norma $l_2$. Utilice\n",
    "valores del parámetro de regularización $\\lambda$ en el rango $[10^7, 10^1]$, variando si estima conveniente.\n",
    "Construya un gráfico que muestre los coeficientes obtenidos como función del parámetro de regularización. Describa lo que observa. (WARNING: Note que la línea 3 y el primer argumento en la línea 9\n",
    "son críticos).\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "import matplotlib.pylab as plt\n",
    "X2 = X.drop('intercept', axis=1,inplace=False)\n",
    "Xtrain = X2[istrain]\n",
    "ytrain = y[istrain]\n",
    "names_regressors = X2.columns\n",
    "alphas_ = np.logspace(7,1,base=10)\n",
    "coefs = []\n",
    "model = Ridge(fit_intercept=True,solver='svd')\n",
    "for a in alphas_:\n",
    "    model.set_params(alpha=a)\n",
    "    model.fit(Xtrain, ytrain)\n",
    "    coefs.append(model.coef_)\n",
    "plt.figure(figsize=(18,9))\n",
    "ax = plt.gca()\n",
    "for y_arr, label in zip(np.squeeze(coefs).T, names_regressors):\n",
    "    plt.plot(alphas_, y_arr, label=label)\n",
    "    plt.legend()\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlim(ax.get_xlim()[::-1]) # reverse axis\n",
    "plt.title('Regularization Path RIDGE')\n",
    "plt.axis('tight')\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\">\n",
    "    **(b)** Ajuste un modelo lineal utilizando el método \"Lasso\", es decir, regularizando con la norma $l_1$. Utilice\n",
    "valores del parámetro de regularización $\\lambda$ en el rango $[10^0, 10^-3]$. Para obtener el código, modifique\n",
    "las líneas 7 y 9 del ejemplo anterior. Construya un gráfico que muestre los coeficientes obtenidos\n",
    "como función del parámetro de regularización. Describa lo que observa. ¿Es más efectivo Lasso para\n",
    "seleccionar atributos?.\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "import matplotlib.pylab as plt\n",
    "X2 = X.drop('intercept', axis=1,inplace=False)\n",
    "Xtrain = X2[istrain]\n",
    "ytrain = y[istrain]\n",
    "names_regressors = X2.columns\n",
    "alphas_ = np.logspace(0,-3,base=10)\n",
    "coefs = []\n",
    "model = Lasso(fit_intercept=True)\n",
    "for a in alphas_:\n",
    "    model.set_params(alpha=a)\n",
    "    model.fit(Xtrain, ytrain)\n",
    "    coefs.append(model.coef_)\n",
    "plt.figure(figsize=(18,9))\n",
    "ax = plt.gca()\n",
    "for y_arr, label in zip(np.squeeze(coefs).T, names_regressors):\n",
    "    plt.plot(alphas_, y_arr, label=label)\n",
    "    plt.legend()\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlim(ax.get_xlim()[::-1]) # reverse axis\n",
    "plt.title('Regularization Path Lasso')\n",
    "plt.axis('tight')\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\">\n",
    "    **(c)** Escogiendo uno de los dos métodos regularizadores anteriores, especificando el porqué, construya un\n",
    "gráfico que muestre el error de entrenamiento y el error de pruebas como función del parámetro de\n",
    "regularizacion. Discuta lo que observa.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtest = X2[np.logical_not(istrain)]\n",
    "ytest = y[np.logical_not(istrain)]\n",
    "alphas_ = np.logspace(7,1,base=10) #np.logspace(0,-3,base=10)\n",
    "coefs = []\n",
    "model = Ridge(fit_intercept=True,solver='svd')  #Lasso(fit_intercept=True) \n",
    "mse_test = []\n",
    "mse_train = []\n",
    "for a in alphas_:\n",
    "    model.set_params(alpha=a)\n",
    "    model.fit(Xtrain, ytrain)\n",
    "    yhat_train = model.predict(Xtrain)\n",
    "    yhat_test = model.predict(Xtest)\n",
    "    mse_train.append(np.mean(np.power(yhat_train - ytrain, 2)))\n",
    "    mse_test.append(np.mean(np.power(yhat_test - ytest, 2)))\n",
    "ax = plt.gca()\n",
    "ax.plot(alphas_,mse_train,label='train error ridge')\n",
    "ax.plot(alphas_,mse_test,label='test error ridge')\n",
    "plt.legend(loc=1)\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlim(ax.get_xlim()[::-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\">\n",
    "    **(d)** Estime el valor del parámetro de regularización en **alguno** de los modelos anteriores haciendo uso de\n",
    "la técnica validación cruzada.\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MSE(y,yhat): return np.mean(np.power(y-yhat,2))\n",
    "Xm = Xtrain.as_matrix()\n",
    "ym = ytrain.as_matrix()\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=10)\n",
    "best_cv_mse = float(\"inf\")\n",
    "model = Ridge(fit_intercept=True,solver='svd')\n",
    "alphas_ = np.logspace(7,1,base=10)\n",
    "for a in alphas_:\n",
    "    model.set_params(alpha=a)\n",
    "    mse_list_k10 = [MSE(model.fit(Xm[train], ym[train]).predict(Xm[val]), ym[val]) for train, val in kf.split(Xm)]\n",
    "    if np.mean(mse_list_k10) < best_cv_mse:\n",
    "        best_cv_mse = np.mean(mse_list_k10)\n",
    "        best_alpha = a\n",
    "        print (\"BEST PARAMETER=%f, MSE(CV)=%f\"%(best_alpha,best_cv_mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  4 Drift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\">\n",
    "    En esta sección se presentarán dos muestras del dataframe utilizado en la actividades anteriores, donde cada\n",
    "una de estas tiene una propiedad distinta ya que son muestreadas en función del valor a predecir (logaritmo\n",
    "del precio de la casa). Por una parte se tiene una pequeña muestra A, la cual es extraída directamente de\n",
    "los datos con los que se trabaja (manteniendo la distribución de esta) y la muestra B, es generada con el\n",
    "propósito de que en cada intervalo del rango de valores haya la misma cantidad de datos aproximadamente\n",
    "(simulando una distribución uniforme). El objetivo es familiarizarse con el concepto de _Transfer Learning_.\n",
    "</p>\n",
    "\n",
    "<p  style=\"text-align: justify;\">\n",
    "    El Aprendizaje por Transferencia (en inglés, _“Transfer Learning”_) es un problema de investigación en el aprendizaje automático que se centra en almacenar el conocimiento adquirido al resolver un problema y aplicarlo a otro problema diferente pero relacionado.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_A = df_scaled.sample(1000,random_state=11)\n",
    "\n",
    "frames = []\n",
    "valor = df_scaled.price\n",
    "length = 0.3\n",
    "for z in np.arange(int(np.min(valor)),int(np.max(valor))+1,length):\n",
    "    #un maximo de 100 datos por intervalo\n",
    "    aux = df_scaled[(df_scaled.price >= z) & (df_scaled.price < z+length)].head(100)\n",
    "    frames.append(aux)\n",
    "    \n",
    "df_B = pd.concat(frames).sample(1000,random_state=11) #crea el dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\">\n",
    "    **(a)** Cree el conjunto de entrenamiento y otro de validación para trabajar cada muestra mediante la técnica\n",
    "de _hold out validation_.\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_A = df_A.iloc[:,1:].values\n",
    "y_A = df_A.price\n",
    "X_B = df_B.iloc[:,1:].values\n",
    "y_B = df_B.price\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Xtrain_A,Xval_A,ytrain_A,yval_A = train_test_split(X_A, y_A, test_size=0.3, random_state=42)\n",
    "Xtrain_B,Xval_B,ytrain_B,yval_B = train_test_split(X_B, y_B, test_size=0.3, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\">\n",
    "    **(b)** Evalúe los dos modelo de regresión lineal que se generan al entrenar con cada muestra. Mida el error\n",
    "de cada modelo sobre ambos conjuntos de validación (A y B). Explique lo que observa.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "\n",
    "LR_A = lm.LinearRegression(fit_intercept = False)\n",
    "LR_B = lm.LinearRegression(fit_intercept = False)\n",
    "\n",
    "LR_A.fit(Xtrain_A, ytrain_A)\n",
    "LR_B.fit(Xtrain_B, ytrain_B)\n",
    "\n",
    "\n",
    "print (\"Regresion lineal\\nCV: \",LR_A.score(Xtrain_A, ytrain_A),\"\\nTest: \",LR_A.score(Xval_A, yval_A))\n",
    "\n",
    "print (\"Regresion lineal\\nCV: \",LR_B.score(Xtrain_B, ytrain_B),\"\\nTest: \",LR_A.score(Xval_B, yval_B))\n",
    "\n",
    "\n",
    "#print(accuracy_score(yval_A, result_A))\n",
    "\n",
    "#print(LR_A.score(Xval_A, yval_A))\n",
    "#print(result_B.score(Xval_B, yval_B))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\">\n",
    "    **(c)** Si tuviera que elegir uno de los dos modelos anteriores para trabajar con data futura, ¿Cuál eligiría y\n",
    "por qué?\n",
    "\n",
    "</p>\n",
    "\n",
    "<p  style=\"text-align: justify;\">\n",
    "    Respuesta\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  5 Detectar enfermedades cardíacas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\">\n",
    "    En el área de la salud, diagnosticar a una persona de una enfermedad de forma rápida y correcta puede llegar\n",
    "a salvarle la vida. Los encargados de realizar estos diagnósticos, son médicos que, observando exámenes y\n",
    "ciertos indicadores, pueden concluir qué enfermedad presenta el paciente. Si el medico se llegase a equivocar,\n",
    "aparte de que el paciente pueda perder la vida, el medico podría ser demandado por negligencia arriesgando\n",
    "a~nos de cárcel o pagar sumas de dinero considerable, es por estas razones que es importante no cometer\n",
    "errores.\n",
    "Pongámonos en el contexto de que usted es contratado para generar un modelo que prediga si es que un\n",
    "paciente presenta una enfermedad cardiaca a partir de ciertos indicadores, tales como la edad, sexo, presión sanguínea, nivel de glicemia, etc. Los datos para trabajar junto a su documentación pueden ser descargados\n",
    "ejecutando los siguientes comandos en un terminal (sistemas UNIX)\n",
    "</p>\n",
    "\n",
    "- wget https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/heart/heart.dat\n",
    "- wget https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/heart/heart.doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\">\n",
    "    Como ayuda se le indica que la variable de máximo ritmo cardíaco alcanzado (_maximum heart rate achieved_)\n",
    "es un buen indicador de detección de enfermedades cardíacas. Por lo que el objetivo es predecir el comportamiento\n",
    "de esta variable en función de las otras, y con esto detectar qué tan distante es el valor real al valor\n",
    "predecido para así luego detectar los posibles _outliers_ (enfermos), que en sí corresponden a pacientes que\n",
    "tienen un comportamiento anormal al resto.\n",
    "\n",
    "</p>\n",
    "\n",
    "<p  style=\"text-align: justify;\">\n",
    "   **(a)** Lea el archivo de datos, cárguelos en un dataframe o matriz, luego divida el dataframe en dos, un\n",
    "dataframe de entrenamiento (70% Datos) y un dataframe de prueba (30% Datos).\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "headers = [\"age\",\"sex\",\"chest_pain\",\"blood_p\",\"serum\",\"blood_s\",\"electro\",\"max_heart\",\"angina\"\n",
    "           ,\"oldpeak\",\"slope\",\"vessel\",\"thal\",\"normal\"]\n",
    "\n",
    "\n",
    "df1 = pd.read_table(\"heart.dat\", header=None, names=headers, sep=\" \", engine=\"python\")\n",
    "mx = df1[\"max_heart\"]\n",
    "df1.drop([\"max_heart\"],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "#print(df2)\n",
    "#variable normal: Absence (1) or Presence (2) of Heart Disease\n",
    "train, test, goal_train, goal_test = train_test_split(df1.loc[:,[\"age\",\"sex\",\"chest_pain\",\"blood_p\",\"serum\",\"blood_s\",\"electro\",\"angina\"\n",
    "           ,\"oldpeak\",\"slope\",\"vessel\",\"thal\"]], \n",
    "                                                      mx, \n",
    "                                                      test_size=0.3, random_state=0)\n",
    "print(train)\n",
    "print(goal_train)\n",
    "\n",
    "\n",
    "df1.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\">\n",
    "   **(b)** Realice una regresión lineal y defina usted una frontera de decisión (umbral) para poder determinar si\n",
    "es que estamos en presencia o no de una enfermedad cardíaca. Mida su desempeño con ambos conjuntos\n",
    "de datos.\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "LR = lm.LinearRegression()\n",
    "LR.fit(train, goal_train)\n",
    "\n",
    "result_train = np.rint(LR.predict(train))\n",
    "result_test = np.rint(LR.predict(test))\n",
    "print(result_train)\n",
    "\n",
    "print (\"Test Score: {:8.8f}\".format(accuracy_score(goal_test, result_test)))\n",
    "print (\"Train Score: {:8.8f}\".format(accuracy_score(goal_train, result_train)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='obj' />\n",
    "# Referencias\n",
    "\n",
    "<ul style=\"text-align: justify;\">\n",
    "    <li>https://www.kaggle.com/harlfoxem/housesalesprediction/discussion/23194</li>\n",
    "    <li>https://rstudio-pubs-static.s3.amazonaws.com/155304_cc51f448116744069664b35e7762999f.html</li>\n",
    "    <li>http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html</li>\n",
    "    <li>https://fisicamatematic.wordpress.com/2011/11/04/minimos-cuadrados</li>\n",
    "    <li></li>\n",
    "    <li></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='obj' />\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
